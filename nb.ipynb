{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.special import logsumexp\n",
    "# from sklearn.feature_selection import SelectKBest, chi2\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file\n",
    "training_df = pd.read_csv('resources/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv('resources/vocabulary.txt', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x = training_df.iloc[:, 1:-1].values # doc vector data\n",
    "y = training_df.iloc[:, -1].values # labels\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "\n",
    "    def __init__(self, alpha=1):\n",
    "        self.alpha = alpha\n",
    "        self.log_prior = None\n",
    "        self.log_likelihood = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Estimate P(Y) using MLE\n",
    "        self.classes, class_counts = np.unique(y, return_counts=True)\n",
    "        self.log_prior = np.log(class_counts / y.shape[0])\n",
    "        # Estimate P(X|Y) using MAP with Dirichlet prior\n",
    "        V = X.shape[1]\n",
    "        self.log_likelihood = np.zeros((len(self.classes), V))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            # Add alpha to each count for smoothing\n",
    "            word_counts = abs(X_c.sum(axis=0) + self.alpha)\n",
    "            total_counts = abs(word_counts.sum() + 1e-9)\n",
    "            self.log_likelihood[i, :] = np.log(word_counts / total_counts)\n",
    "\n",
    "    def predict(self, Xnew):\n",
    "        # Calculate log-probabilities for each class\n",
    "        log_probs = np.zeros(len(self.classes))\n",
    "        for i, c in enumerate(self.classes):\n",
    "            log_probs[i] = self.log_prior[i] + \\\n",
    "                (self.log_likelihood[i, :] * Xnew).sum()\n",
    "\n",
    "        # Return the class with the highest log-probability\n",
    "        return self.classes[np.argmax(log_probs)]\n",
    "\n",
    "    def find_accuracy(original_df, pred_df):\n",
    "        num_correct = 0\n",
    "        index = 0\n",
    "        for i, doc in pred_df.iterrows():\n",
    "            if (doc['pred'] == original_df.iloc[index, -1]):\n",
    "                num_correct += 1\n",
    "            index += 1\n",
    "\n",
    "        return num_correct/len(original_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('resources/naive_bayes_model.pkl'):\n",
    "  # Load the saved model from the file\n",
    "  with open('resources/naive_bayes_model.pkl', 'rb') as file:\n",
    "    nb = pickle.load(file)\n",
    "\n",
    "else:\n",
    "  nb = NaiveBayesClassifier()\n",
    "  nb.fit(x_train, y_train)\n",
    "\n",
    "  # Save the trained model to a file\n",
    "  with open('resources/naive_bayes_model.pkl', 'wb') as file:\n",
    "    pickle.dump(nb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8158333333333333\n"
     ]
    }
   ],
   "source": [
    "validation_preds = np.array([nb.predict(x) for x in x_validation])\n",
    "accuracy = np.mean(validation_preds == y_validation)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_df = pd.read_csv('resources/testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = testing_df.iloc[:, 1:].values\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.array([int(nb.predict(x)) for x in x_test]).tolist()\n",
    "ids = list(testing_df.iloc[:, :1].values)\n",
    "\n",
    "if int(ids[0][0]) != 12001:\n",
    "    ids.insert(0, np.array([12001]))\n",
    "    test_preds.insert(0, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['id', 'class'])\n",
    "\n",
    "    for id, pred in zip(ids, test_preds):\n",
    "        writer.writerow([id[0], pred])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(x, y, words, stopwords, penalty=0.5):\n",
    "    n_samples, n_features = x.shape\n",
    "    n_classes = len(np.unique(y))\n",
    "\n",
    "    # Compute the frequency of each word in each class\n",
    "    word_freq = np.zeros((n_features, n_classes))\n",
    "    for i in range(n_classes):\n",
    "        X_class = x[y == i, :]\n",
    "        word_freq[:, i] = np.sum(X_class, axis=0)\n",
    "\n",
    "    # Compute the total number of documents in each class and the total number of documents\n",
    "    class_freq = np.sum(word_freq, axis=0)\n",
    "    total_freq = np.sum(class_freq)\n",
    "\n",
    "    # Compute the MI between each word and each class\n",
    "    mi_scores = np.zeros(n_features)\n",
    "    for j in range(n_features):\n",
    "        n_j = np.sum(x[:, j] > 0)\n",
    "        for i in range(n_classes):\n",
    "            n_ij = word_freq[j, i]\n",
    "            if n_ij == 0:\n",
    "                continue\n",
    "            p_ij = n_ij / n_samples\n",
    "            p_i = class_freq[i] / n_samples\n",
    "            p_j = n_j / n_samples\n",
    "            mi_scores[j] += p_ij * np.log2(p_ij / (p_i * p_j))\n",
    "\n",
    "        # Penalize stopwords in the MI score\n",
    "        if words[j] in stopwords:\n",
    "            mi_scores[j] -= penalty\n",
    "\n",
    "    # Normalize the MI scores to have a range of [0, 1]\n",
    "    mi_scores_norm = (mi_scores - np.min(mi_scores)) / \\\n",
    "        (np.max(mi_scores) - np.min(mi_scores))\n",
    "\n",
    "    return mi_scores_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "word_values = words.iloc[:, 0].values\n",
    "mi = mutual_information(x_train, y_train, word_values, stop_words, penalty=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Words\n",
      "                   0\n",
      "27987         layton\n",
      "27990      bloodshot\n",
      "27992        bwsmith\n",
      "22500         guykuo\n",
      "28059  polypropylene\n",
      "27897           maxx\n",
      "28063        prothan\n",
      "27804    shatterstar\n",
      "26798           khoh\n",
      "56592            jth\n",
      "Least Informative Words\n",
      "        0\n",
      "921  have\n",
      "29     in\n",
      "32     to\n",
      "41     it\n",
      "28    the\n",
      "977    am\n",
      "51   with\n",
      "143    be\n",
      "437  only\n",
      "59     is\n",
      "MI Scores of Stopwords\n",
      "of 0.06192881235371666\n",
      "from 0.10182668153081469\n",
      "and 0.09482550541296586\n",
      "other 0.11191653664509267\n",
      "are 0.1077173114351087\n",
      "the 0.03769413396773495\n",
      "in 0.0011474582383969984\n",
      "to 0.029168881650963485\n",
      "it 0.037320953655183335\n",
      "on 0.08786818466986307\n",
      "their 0.13880554679644946\n",
      "but 0.06410081985744231\n",
      "with 0.0546548631953915\n",
      "is 0.06138748682033983\n",
      "can 0.10120777093539329\n",
      "for 0.07869139565389022\n",
      "who 0.14420638259912863\n",
      "so 0.09665312338971446\n",
      "such 0.16229772008042267\n",
      "by 0.16929777899011295\n",
      "itself 0.17761658538062886\n",
      "or 0.13059632422789824\n",
      "below 0.1998684957315541\n",
      "an 0.08724368290381708\n",
      "which 0.11758837994712117\n",
      "be 0.05468112421280088\n",
      "they 0.17923433691049126\n",
      "that 0.08595923888657452\n",
      "all 0.11627170709629156\n",
      "any 0.15250723975534675\n",
      "this 0.07532000344408517\n",
      "his 0.16936597802158457\n",
      "at 0.11399903759680005\n",
      "very 0.1490984452696076\n",
      "he 0.1770921442915734\n",
      "about 0.08173924444983838\n",
      "than 0.14587093759622974\n",
      "had 0.1814398892305625\n",
      "some 0.0970642059129889\n",
      "when 0.13731189808309596\n",
      "its 0.18677777617356411\n",
      "after 0.1319977215253624\n",
      "into 0.12786714319614761\n",
      "as 0.07629966943295988\n",
      "she 0.21325318137980617\n",
      "again 0.1625595377122235\n",
      "under 0.16037818934740958\n",
      "own 0.1263290228695322\n",
      "only 0.055003326007263514\n",
      "down 0.17951554140476472\n",
      "more 0.10077770991011925\n",
      "has 0.08969598294019641\n",
      "been 0.12179372258571051\n",
      "if 0.10055310588449552\n",
      "you 0.10558099619708076\n",
      "ll 0.17544507105242457\n",
      "what 0.13172625962494272\n",
      "both 0.13397035812866295\n",
      "most 0.15383278480359558\n",
      "against 0.15433881944287003\n",
      "while 0.1605314061083153\n",
      "over 0.14790091753469142\n",
      "was 0.1672060769950254\n",
      "were 0.1854184266516717\n",
      "through 0.15949937696159552\n",
      "those 0.16055219354079825\n",
      "not 0.07415032122304313\n",
      "above 0.16430272731810963\n",
      "why 0.12916857612916227\n",
      "them 0.16651516058713445\n",
      "there 0.15141339973639203\n",
      "will 0.13924057930868108\n",
      "our 0.1884841878443626\n",
      "we 0.18470896847865204\n",
      "did 0.15902917763172544\n",
      "these 0.14103571988475422\n",
      "just 0.1180448819778076\n",
      "me 0.16677881123371383\n",
      "don 0.12736626929358827\n",
      "do 0.07013800394378882\n",
      "no 0.09269028815214861\n",
      "didn 0.20229119400835888\n",
      "here 0.12214291740298976\n",
      "off 0.15302147047524153\n",
      "up 0.1135644567267184\n",
      "now 0.12364257977841589\n",
      "have 0.0\n",
      "out 0.14266954465300005\n",
      "should 0.14960887916952434\n",
      "your 0.1452596798775365\n",
      "am 0.0427979134336364\n",
      "between 0.1277710905302869\n",
      "my 0.11939687504209018\n",
      "then 0.14597589564625948\n",
      "same 0.10334853378526727\n",
      "because 0.1541226283204587\n",
      "ve 0.12889295221790714\n",
      "each 0.17725988453413624\n",
      "how 0.11690263818833346\n",
      "does 0.08884687409161784\n",
      "before 0.16087084378274297\n",
      "where 0.1438429064736896\n",
      "few 0.10963357405938703\n",
      "too 0.16245882376049695\n",
      "until 0.1596108606041428\n",
      "wouldn 0.16695600281349351\n",
      "couldn 0.20465538023881708\n",
      "isn 0.159384030403323\n",
      "during 0.19089113345028078\n",
      "myself 0.19574930176651248\n",
      "doesn 0.10212459600802769\n",
      "him 0.19838828501231973\n",
      "shouldn 0.18965261286962165\n",
      "once 0.16079381709294066\n",
      "being 0.13270338830307474\n",
      "doing 0.1575812882913161\n",
      "yourself 0.19855477820559622\n",
      "ourselves 0.2094561737134124\n",
      "re 0.18197750314937416\n",
      "themselves 0.18791973830182512\n",
      "ain 0.20458185593376713\n",
      "further 0.1901212542032585\n",
      "her 0.21235229152494203\n",
      "won 0.18401999151371673\n",
      "yourselves 0.21652366588228814\n",
      "having 0.1519736989211641\n",
      "whom 0.20850093873794168\n",
      "haven 0.1584359309537554\n",
      "yours 0.1849489585445803\n",
      "weren 0.21144713259246792\n",
      "aren 0.1737187926233059\n",
      "himself 0.2114647207513573\n",
      "herself 0.21648427138490905\n",
      "nor 0.19559415313109696\n",
      "ours 0.21351843618171845\n",
      "wasn 0.19672690424810302\n",
      "hadn 0.21738648323058757\n",
      "hasn 0.2069336452373678\n",
      "theirs 0.21514097174498772\n",
      "ma 0.21655085480260225\n",
      "shan 0.22207722204224242\n",
      "hers 0.22203780462986572\n",
      "needn 0.22217797736223402\n",
      "mustn 0.2216811699081521\n"
     ]
    }
   ],
   "source": [
    "# print table of 10 most informative and 10 least informative words\n",
    "print('Most Informative Words')\n",
    "print(words.iloc[np.argsort(mi)[-10:]])\n",
    "print('Least Informative Words')\n",
    "print(words.iloc[np.argsort(mi)[:10]])\n",
    "\n",
    "# write 100 most informative words to file\n",
    "with open('resources/most_informative_words.txt', 'w') as file:\n",
    "    for word in words.iloc[np.argsort(mi)[-100:]].values:\n",
    "        file.write(word[0] + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = np.unique(validation_df.iloc[:, -1].values, return_counts=False)\n",
    "# cm = confusion_matrix(validation_pred_df['pred'].values, validation_df.iloc[:, -1].values, labels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cm)\n",
    "# sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "# plt.xlabel('Predicted label')\n",
    "# plt.ylabel('True label')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
